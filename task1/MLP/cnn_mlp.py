import os
import glob
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from sklearn.metrics import precision_score, recall_score, f1_score
import numpy as np
import time
import tqdm

# ================= é…ç½®å‚æ•° (é’ˆå¯¹ 4GB æ˜¾å­˜ä¼˜åŒ–) =================
CONFIG = {
    'img_size': 256,        # ä¿æŒ 256ï¼Œé€šè¿‡ GAP å’Œ AMP èŠ‚çœæ˜¾å­˜
    'batch_size': 64,       # ä¼˜åŒ–åæ˜¾å­˜å ç”¨é™ä½ï¼Œå¯ä»¥å°è¯•å¼€å¤§ BatchSize åŠ é€Ÿ
    'lr': 0.001,
    'epochs': 40,
    'device': 'cuda' if torch.cuda.is_available() else 'cpu',
    'train_dir': r'D:\table\ml\project\dataset\train', 
    'test_dir': r'D:\table\ml\project\dataset\test',
    'pos_weight': 9.0,
    'num_workers': 4        # ã€ä¼˜åŒ–ã€‘å¼€å¯å¤šè¿›ç¨‹è¯»å–
}

# å¼€å¯ CUDNN åŠ é€Ÿ
torch.backends.cudnn.benchmark = True 

# ================= æ•°æ®é›†ç±» (ä¿æŒä¸å˜) =================
class GlassDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.img_dir = os.path.join(root_dir, 'img')
        self.txt_dir = os.path.join(root_dir, 'txt')
        self.img_paths = glob.glob(os.path.join(self.img_dir, '*.png'))
        self.transform = transform
        
    def __len__(self):
        return len(self.img_paths)
    
    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        filename = os.path.basename(img_path)
        txt_path = os.path.join(self.txt_dir, filename.replace('.png', '.txt'))
        label = 1.0 if os.path.exists(txt_path) else 0.0
        
        image = Image.open(img_path).convert('L')
        if self.transform:
            image = self.transform(image)
        return image, torch.tensor(label, dtype=torch.float32)

# ================= æ¨¡å‹æ¶æ„ï¼šè½»é‡åŒ–ä¼˜åŒ–ç‰ˆ =================
class OptimizedCNN(nn.Module):
    def __init__(self):
        super(OptimizedCNN, self).__init__()
        
        # é€šé“æ•°å‡åŠç­–ç•¥ (32->16, 64->32...) ä»¥é€‚åº” 4GB æ˜¾å­˜å¹¶åŠ é€Ÿ
        # å¦‚æœè§‰å¾—ç²¾åº¦ä¸å¤Ÿï¼Œå¯ä»¥æŠŠé€šé“æ•°æ”¹å›å» (16->32, 32->64...)
        self.features = nn.Sequential(
            # Block 1
            nn.Conv2d(1, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(),
            nn.Conv2d(16, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            # Block 2
            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),
            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            # Block 3
            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),
            nn.MaxPool2d(2, 2),

            # Block 4
            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),
            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            # Block 5
            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),
            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),
            nn.MaxPool2d(2, 2),
        )
        
        # ã€ä¼˜åŒ–å…³é”®ã€‘å…¨å±€å¹³å‡æ± åŒ– (Global Average Pooling)
        # æ— è®ºå‰é¢ç‰¹å¾å›¾å¤šå¤§ï¼Œè¿™é‡Œéƒ½å˜æˆ [batch, 256, 1, 1]
        self.gap = nn.AdaptiveAvgPool2d((1, 1))
        
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(256, 64), # å‚æ•°é‡æå°ï¼š256*64ï¼Œä¸å†æ˜¯ 32768*1024
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(64, 1)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.gap(x) # å‹ç¼©ç‰¹å¾
        x = self.classifier(x)
        return x

# ================= è®­ç»ƒä¸è¯„ä¼°å‡½æ•° (é›†æˆ AMP) =================
def train_model():
    # æ•°æ®å¢å¼º
    train_transform = transforms.Compose([
        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])
    
    test_transform = transforms.Compose([
        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    train_ds = GlassDataset(CONFIG['train_dir'], transform=train_transform)
    test_ds = GlassDataset(CONFIG['test_dir'], transform=test_transform)
    
    # ã€ä¼˜åŒ–ã€‘å¼€å¯ pin_memory å’Œ num_workers
    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], 
                              shuffle=True, num_workers=CONFIG['num_workers'], pin_memory=True)
    test_loader = DataLoader(test_ds, batch_size=CONFIG['batch_size'], 
                             shuffle=False, num_workers=CONFIG['num_workers'], pin_memory=True)

    model = OptimizedCNN().to(CONFIG['device'])
    
    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([CONFIG['pos_weight']]).to(CONFIG['device']))
    optimizer = optim.Adam(model.parameters(), lr=CONFIG['lr'])
    
    # ã€ä¼˜åŒ–ã€‘æ··åˆç²¾åº¦ Scaler
    scaler = torch.cuda.amp.GradScaler()

    print(f"å¼€å§‹è®­ç»ƒï¼Œè®¾å¤‡: {CONFIG['device']} | AMP: On | Num_workers: {CONFIG['num_workers']}")
    
    best_f1 = 0
    start_time = time.time()

    for epoch in range(CONFIG['epochs']):
        #print(f"\nEpoch {epoch+1}/{CONFIG['epochs']}")
        model.train()
        total_loss = 0
        
        for imgs, labels in tqdm.tqdm(train_loader, desc=f"Epoch {epoch+1}/{CONFIG['epochs']}", leave=False):
            imgs = imgs.to(CONFIG['device'], non_blocking=True) # non_blocking åŠ é€Ÿæ•°æ®ä¼ è¾“
            labels = labels.to(CONFIG['device'], non_blocking=True).unsqueeze(1)
            
            optimizer.zero_grad()
            
            # ã€ä¼˜åŒ–ã€‘æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
            with torch.cuda.amp.autocast():
                outputs = model(imgs)
                loss = criterion(outputs, labels)
            
            # ã€ä¼˜åŒ–ã€‘æ··åˆç²¾åº¦åå‘ä¼ æ’­
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            total_loss += loss.item()

        # éªŒè¯ (ä¹Ÿå¯ä»¥ç”¨ AMP åŠ é€Ÿæ¨ç†)
        model.eval()
        all_labels = []
        all_preds = []
        test_loss = 0
        
        with torch.no_grad():
            for imgs, labels in test_loader:
                imgs = imgs.to(CONFIG['device'], non_blocking=True)
                labels = labels.to(CONFIG['device'], non_blocking=True).unsqueeze(1)
                
                with torch.cuda.amp.autocast(): # æ¨ç†ä¹Ÿå¼€ AMP
                    outputs = model(imgs)
                    loss = criterion(outputs, labels)
                
                preds = (torch.sigmoid(outputs) > 0.5).float().cpu().numpy()
                all_labels.extend(labels.cpu().numpy()) # è®°å¾—ç§»å› CPU
                all_preds.extend(preds)
                test_loss += loss.item()

        # è®¡ç®—æŒ‡æ ‡
        # æ³¨æ„ï¼šè¿™é‡ŒæŠŠ list è½¬ numpy å†ç®—ï¼Œé˜²æ­¢æŠ¥é”™
        all_labels = np.array(all_labels).flatten()
        all_preds = np.array(all_preds).flatten()
        
        f1 = f1_score(all_labels, all_preds, zero_division=0)
        p = precision_score(all_labels, all_preds, zero_division=0)
        r = recall_score(all_labels, all_preds, zero_division=0)
        
        epoch_time = time.time() - start_time
        print(f"Epoch [{epoch+1}/{CONFIG['epochs']}] ({epoch_time:.0f}s) "
              f"Train Loss: {total_loss/len(train_loader):.4f} | Test Loss: {test_loss/len(test_loader):.4f} | "
              f"F1: {f1:.4f} (P: {p:.4f}, R: {r:.4f})")
        
        if f1 > best_f1:
            best_f1 = f1
            torch.save(model.state_dict(), 'best_optimized_cnn.pth')
            print("--> ğŸ‘‘ ä¿æŒæœ€ä½³æ¨¡å‹")

if __name__ == '__main__':
    # è§£å†³ Windows ä¸‹ num_workers æŠ¥é”™çš„å…³é”®
    torch.multiprocessing.freeze_support() 
    train_model()